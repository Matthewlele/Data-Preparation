{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Analysis of the Most Streamed Spotify Songs 2023 Dataset\n",
    "\n",
    "In this notebook, we will perform an explorative analysis of the [Most Streamed Spotify Songs 2023 dataset](https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023/data). This dataset contains information about the most streamed songs on Spotify in the year 2023. \n",
    "\n",
    "Our goal is to gain insights into the characteristics of these songs and identify any trends or patterns that may exist. We will start by loading and cleaning the data, and then proceed to perform various analyses and visualizations.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spotify-2023.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicates \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check basic info about values in each column\n",
    "columns_info = pd.DataFrame(df.dtypes, columns=['Data Type'])\n",
    "columns_info['Null Values'] = df.isnull().sum()\n",
    "columns_info['Unique Values'] = df.nunique()\n",
    "columns_info['Count'] = df.count()\n",
    "columns_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check percentage count for each key value\n",
    "df['key'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of objects with more than 1 missing value\n",
    "df[df.isnull().sum(axis=1) > 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['in_shazam_charts'] = df['in_shazam_charts'].str.replace(',', '')\n",
    "df['in_shazam_charts'] = pd.to_numeric(df['in_shazam_charts'])\n",
    "\n",
    "columns_info = pd.DataFrame(df.dtypes, columns=['Data Type'])\n",
    "columns_info['Null Values'] = df.isnull().sum()\n",
    "columns_info['Unique Values'] = df.nunique()\n",
    "columns_info['Count'] = df.count()\n",
    "columns_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies of categorical attributes of the dataset (artist(s)_name, track_name, key, mode)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freqencies for each categorical attribute if it has more than 10 unique values than top 10 freqs\n",
    "cat_columns =  ['track_name', 'key', 'mode']\n",
    "for col in cat_columns:\n",
    "    freq_df = pd.DataFrame()\n",
    "    freq_df['counts'] = df[col].value_counts()\n",
    "    freq_df['percentage'] = df[col].value_counts(normalize=True).apply(lambda x: round(x*100,2))\n",
    "    if df[col].nunique() > 20:\n",
    "        print(freq_df.head(10))\n",
    "    else:\n",
    "        print(freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of individual artists and respective frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['artist(s)_name']\n",
    "df_expanded_on_artists = df['artist(s)_name'].str.split(',', expand=True).stack().reset_index(level=1, drop=True)\n",
    "df_expanded_on_artists = df_expanded_on_artists.str.strip()\n",
    "\n",
    "freq_df = pd.DataFrame()\n",
    "freq_df['counts'] = df_expanded_on_artists.value_counts()\n",
    "freq_df['percentage'] = df_expanded_on_artists.value_counts(normalize=True).apply(lambda x: round(x*100,2))\n",
    "freq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore numerical values by range, median, mean, std, median\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_charts_without_null = df[(df['in_shazam_charts'] > 0) & (df['in_deezer_charts'] > 0) & (df['in_spotify_charts'] > 0) & (df['in_apple_charts'] > 0)]\n",
    "df_charts_without_null.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['streams'].str.isnumeric().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df['streams'].str.isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete that row as 1 row is not significant\n",
    "df = df.drop(df[~df['streams'].str.isnumeric()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert streams to numeric\n",
    "df['streams'] = pd.to_numeric(df['streams'])\n",
    "df['streams'].describe().apply('{0:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['in_deezer_playlists'].str.isnumeric().all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df['in_deezer_playlists'].str.isnumeric()]['in_deezer_playlists']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['in_deezer_playlists'] = df['in_deezer_playlists'].str.replace(',', '')\n",
    "df['in_deezer_playlists'] = pd.to_numeric(df['in_deezer_playlists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df['released_year'].plot.hist(log=True, bins=20)\n",
    "fig.set_xlabel('Year')\n",
    "fig.set_title('Histogram of released_year frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric columns\n",
    "corr = df.select_dtypes(include=['float64', 'int64']).corr()\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discrete_streams'] = pd.cut(df['streams'], [0, 250e6, 500e6, 10e9], labels=['low', 'medium', 'high'])\n",
    "df['discrete_streams'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical attributes\n",
    "interesting_cols = [ 'streams', 'in_spotify_charts', 'in_spotify_playlists', 'released_year', 'bpm', 'energy_%', 'danceability_%', 'liveness_%', 'valence_%', 'acousticness_%', 'speechiness_%']\n",
    "sns.pairplot(df, x_vars=interesting_cols, y_vars=interesting_cols,\n",
    "            hue='discrete_streams')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discrete_years'] = pd.cut(df['released_year'], [0, 2000,2010,2025], labels=['before 2000', '2000-2010', 'after 2010'])\n",
    "df['discrete_years'].value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(df, x='streams', y='discrete_years', color='discrete_years',box=True, orientation='h', title='Distribution of streams for year groups')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "px.scatter_3d(df, x='bpm', y='streams', z='energy_%', color='discrete_years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring categorical attributes Key and Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key mapping [0,1,2,3,4,5,6,7,8,9,10,11],['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A','A#','B']\n",
    "data_grouped_by_key = df.groupby('key')['streams'].sum().reset_index().sort_values('streams', ascending=False)\n",
    "data_grouped_by_key.plot.bar(x='key', y='streams', colormap='Paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of streams for individual modes\n",
    "px.box(df, x='streams', y='mode', color='mode', orientation='h', title='Distribution of streams for individual modes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df, x='streams', y='key', color='key', orientation='h', title='Distribution of streams for individual keys')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with paired t test with different variance\n",
    "from scipy.stats import ttest_ind\n",
    "from itertools import combinations\n",
    "# test for each pair of keys once\n",
    "# create pairs of keys without repetition\n",
    "key_pairs = set(combinations(df['key'].unique(), 2))\n",
    "for key_pair in key_pairs:\n",
    "        i, j  = key_pair\n",
    "        df_i = df[df['key'] == i]\n",
    "        df_j = df[df['key'] == j]\n",
    "        pvalue = ttest_ind(df_i['streams'], df_j['streams'], equal_var=False)[1]\n",
    "        if pvalue > 0.05:\n",
    "            print(f'The means of {i} - {j} are the same.(p-value {pvalue} > 0.05)')\n",
    "        else:\n",
    "            print(f'The means of {i} - {j} are different.(p-value {pvalue} < 0.05)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(df, x='streams', y='released_month', z='in_spotify_charts', color='key', title='Distribution of streams for individual keys and modes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count tracks by keys in top 10 tracks by streams \n",
    "df.dropna(subset=['key','in_shazam_charts'], inplace=True)\n",
    "\n",
    "keys = df['key'].unique()\n",
    "bins = [0, 10, 30, 50, 100, len(df.index)]\n",
    "sorted_by_streams = df.sort_values('streams', ascending=False)\n",
    "topX_df = pd.DataFrame(columns=['topX', 'key', 'count','percentage'])\n",
    "lastX_df = pd.DataFrame(columns=['lastX', 'key', 'count','percentage'])\n",
    "for i, topX in enumerate(bins):\n",
    "    if i + 1 >= len(bins):\n",
    "        break\n",
    "    topX_tracks = sorted_by_streams.head(bins[i+1])\n",
    "    lastX_tracks = sorted_by_streams.tail(bins[i+1])\n",
    "    for key in keys: \n",
    "        count = topX_tracks[topX_tracks['key'] == key].count()['key']\n",
    "        percentage = topX_tracks[topX_tracks['key'] == key].count()['key'] / topX_tracks.count()['key']\n",
    "        topX_df.loc[len(topX_df.index)] = [bins[i+1], key, count, percentage]\n",
    "        count = lastX_tracks[lastX_tracks['key'] == key].count()['key']\n",
    "        percentage = lastX_tracks[lastX_tracks['key'] == key].count()['key'] / lastX_tracks.count()['key']\n",
    "        lastX_df.loc[len(lastX_df.index)] = [bins[i+1], key, count, percentage]\n",
    "pd.concat([topX_df.head(11),lastX_df.head(11)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot percentage plot for each key\n",
    "fig, axs = plt.subplots(2, figsize=(12,6))\n",
    "topX_ticks = [f'Top {bin}' for bin in bins[1:]]\n",
    "lastX_ticks = [f'Last {bin}' for bin in bins[1:]]\n",
    "topX_axs = axs[0]\n",
    "lastX_axs = axs[1]\n",
    "\n",
    "for key in keys: \n",
    "    data = topX_df[topX_df['key'] == key]\n",
    "    \n",
    "    topX_axs.set_ylim(0, 0.6)\n",
    "    topX_axs.scatter(topX_ticks, data['percentage'], label=key)\n",
    "    topX_axs.plot(topX_ticks, data['percentage'], alpha=0.2)\n",
    "    topX_axs.set_ylabel('percentage')\n",
    "    topX_axs.set_xlabel('topX')\n",
    "    topX_axs.legend(loc='lower right')\n",
    "\n",
    "    data = lastX_df[lastX_df['key'] == key]\n",
    "   \n",
    "    lastX_axs.set_ylim(0, 0.5)\n",
    "    lastX_axs.scatter(lastX_ticks, data['percentage'], label=key)\n",
    "    lastX_axs.plot(lastX_ticks, data['percentage'], alpha=0.2)\n",
    "    lastX_axs.set_ylabel('percentage')\n",
    "    lastX_axs.set_xlabel('lastX')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut top 100 songs by streams\n",
    "sorted_by_streams = sorted_by_streams.reset_index()\n",
    "sorted_by_streams['top100'] = pd.cut(sorted_by_streams.index, [0, 100, len(sorted_by_streams.index)], labels=['top100', 'rest'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(sorted_by_streams, x='danceability_%', y='acousticness_%', z='energy_%', color='discrete_years')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(sorted_by_streams,log_y=True, x='key', color='top100', title='Histogram of streams for individual keys and modes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Isolation forest to get outliers for numeric attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import IsolationForest    \n",
    "def train_and_predict_if(df, feature):\n",
    "    rng = np.random.RandomState(42)\n",
    "    clf = IsolationForest(max_samples=750, random_state=rng)\n",
    "    clf.fit(df[[feature]])\n",
    "    pred = clf.predict(df[[feature]])\n",
    "    scores = clf.decision_function(df[[feature]])\n",
    "    stats = pd.DataFrame()\n",
    "    stats['val'] = df[feature]\n",
    "    stats['score'] = scores\n",
    "    stats['outlier'] = pred\n",
    "    stats['min'] = df[feature].min()\n",
    "    stats['max'] = df[feature].max()\n",
    "    stats['mean'] = df[feature].mean()\n",
    "    stats['feature'] = [feature] * len(df)\n",
    "    return stats\n",
    "\n",
    "def print_outliers(df, feature, n):\n",
    "    print(feature)\n",
    "    print(df[feature].head(n).to_string(), \"\\n\")\n",
    "\n",
    "num_columns = df.select_dtypes(include=['float64', 'int64'])\n",
    "result = pd.DataFrame()\n",
    "for feature in num_columns:\n",
    "    stats = train_and_predict_if(df, feature)\n",
    "    result = pd.concat([result, stats])\n",
    "\n",
    "outliers = {team: grp.drop('feature', axis=1)\n",
    "            for team, grp in result.sort_values(by='score').groupby('feature')}\n",
    "\n",
    "n_outliers = 10\n",
    "for feature in num_columns:\n",
    "    print_outliers(outliers, feature, n_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no signaificant outliers for any of the numerical attributes. IsoForest score for each value < 0.36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting outliers for numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def IQR_outlier_detection(df, feature):\n",
    "    if df[feature].dtype != 'int64' and df[feature].dtype != 'float64':\n",
    "        return pd.DataFrame()\n",
    "    IQR = df[feature].quantile(0.75) - df[feature].quantile(0.25)\n",
    "    lower_bound = df[feature].quantile(0.25) - (IQR * 1.5)\n",
    "    upper_bound = df[feature].quantile(0.75) + (IQR * 1.5)\n",
    "    return lower_bound, upper_bound, df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "\n",
    "IQR_outliers_stats = pd.DataFrame({'feature': [], 'count': []})\n",
    "for attribute in num_columns:\n",
    "    lower_bound, upper_bound, outliers = IQR_outlier_detection(df, attribute)\n",
    "    IQR_outliers_stats = pd.concat([IQR_outliers_stats, pd.DataFrame({'feature': [attribute], 'count': [len(outliers)]})])\n",
    "    \n",
    "   \n",
    "IQR_outliers_stats.reset_index(drop=True, inplace=True)\n",
    "IQR_outliers_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-score outlier detection\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def z_score_outlier_detection(df, feature):\n",
    "    if df[feature].dtype != 'int64' and df[feature].dtype != 'float64':\n",
    "        return pd.DataFrame()\n",
    "    z = np.abs(zscore(df[feature]))\n",
    "    return df[(z > 3)]\n",
    "\n",
    "z_score_outliers_stats = pd.DataFrame({'feature': [], 'count': []})\n",
    "for attribute in num_columns:\n",
    "    outliers = z_score_outlier_detection(df, attribute)\n",
    "    z_score_outliers_stats = pd.concat([z_score_outliers_stats, pd.DataFrame({'feature': [attribute], 'count': [len(outliers)]})])\n",
    "\n",
    "z_score_outliers_stats.reset_index(drop=True, inplace=True)\n",
    "z_score_outliers_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined outlier detection feature z-score IQR from dataframes\n",
    "combined_outliers_stats = pd.merge(IQR_outliers_stats, z_score_outliers_stats, on='feature', how='outer', )\n",
    "combined_outliers_stats.rename(columns={'count_x': 'IQR', 'count_y': 'z-score'}, inplace=True)\n",
    "combined_outliers_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
